{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages for this module\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse,urlencode\n",
    "import ipaddress\n",
    "import re\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import whois\n",
    "import urllib\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Prepare Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phish_id</th>\n",
       "      <th>url</th>\n",
       "      <th>phish_detail_url</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>verified</th>\n",
       "      <th>verification_time</th>\n",
       "      <th>online</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7809030</td>\n",
       "      <td>https://comunicazionerestrizione.com/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-10-03T11:09:31+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-10-03T11:13:42+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7809024</td>\n",
       "      <td>https://att-109330.weeblysite.com/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-10-03T11:02:10+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-10-03T11:13:42+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7809023</td>\n",
       "      <td>http://att-109330.weeblysite.com/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-10-03T11:02:09+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-10-03T11:13:42+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7809022</td>\n",
       "      <td>https://att-107934.weeblysite.com/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-10-03T11:02:08+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-10-03T11:13:42+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7809021</td>\n",
       "      <td>https://att-team-100932.weeblysite.com/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-10-03T11:01:52+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-10-03T11:13:42+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phish_id                                      url  \\\n",
       "0   7809030    https://comunicazionerestrizione.com/   \n",
       "1   7809024       https://att-109330.weeblysite.com/   \n",
       "2   7809023        http://att-109330.weeblysite.com/   \n",
       "3   7809022       https://att-107934.weeblysite.com/   \n",
       "4   7809021  https://att-team-100932.weeblysite.com/   \n",
       "\n",
       "                                    phish_detail_url  \\\n",
       "0  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "1  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "2  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "3  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "4  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "\n",
       "             submission_time verified          verification_time online target  \n",
       "0  2022-10-03T11:09:31+00:00      yes  2022-10-03T11:13:42+00:00    yes  Other  \n",
       "1  2022-10-03T11:02:10+00:00      yes  2022-10-03T11:13:42+00:00    yes  Other  \n",
       "2  2022-10-03T11:02:09+00:00      yes  2022-10-03T11:13:42+00:00    yes  Other  \n",
       "3  2022-10-03T11:02:08+00:00      yes  2022-10-03T11:13:42+00:00    yes  Other  \n",
       "4  2022-10-03T11:01:52+00:00      yes  2022-10-03T11:13:42+00:00    yes  Other  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the phishing URLs data to dataframe\n",
    "data0 = pd.read_csv(\"verified_online.csv\")\n",
    "data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63663, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phish_id</th>\n",
       "      <th>url</th>\n",
       "      <th>phish_detail_url</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>verified</th>\n",
       "      <th>verification_time</th>\n",
       "      <th>online</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7683062</td>\n",
       "      <td>https://dawq.wlyhxj477.workers.dev/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-08-23T22:07:14+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-08-23T22:10:39+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7743195</td>\n",
       "      <td>http://www.veiscsveccaacsriri.ovarisveaseccvso...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-09-09T17:51:01+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-09-09T18:06:17+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>NICOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7753195</td>\n",
       "      <td>http://www.saaccesaiccairccrsoorna.seieascaaci...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-09-13T09:39:00+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-09-13T14:42:30+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>NICOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7775923</td>\n",
       "      <td>https://fpxrjrjqzk.duckdns.org/</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-09-17T00:04:34+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-09-17T01:06:23+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7771613</td>\n",
       "      <td>http://www.viaaveceesvcceei.visavscverarsi.rol...</td>\n",
       "      <td>http://www.phishtank.com/phish_detail.php?phis...</td>\n",
       "      <td>2022-09-15T19:44:01+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>2022-09-15T21:53:16+00:00</td>\n",
       "      <td>yes</td>\n",
       "      <td>NICOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phish_id                                                url  \\\n",
       "0   7683062                https://dawq.wlyhxj477.workers.dev/   \n",
       "1   7743195  http://www.veiscsveccaacsriri.ovarisveaseccvso...   \n",
       "2   7753195  http://www.saaccesaiccairccrsoorna.seieascaaci...   \n",
       "3   7775923                    https://fpxrjrjqzk.duckdns.org/   \n",
       "4   7771613  http://www.viaaveceesvcceei.visavscverarsi.rol...   \n",
       "\n",
       "                                    phish_detail_url  \\\n",
       "0  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "1  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "2  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "3  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "4  http://www.phishtank.com/phish_detail.php?phis...   \n",
       "\n",
       "             submission_time verified          verification_time online target  \n",
       "0  2022-08-23T22:07:14+00:00      yes  2022-08-23T22:10:39+00:00    yes  Other  \n",
       "1  2022-09-09T17:51:01+00:00      yes  2022-09-09T18:06:17+00:00    yes  NICOS  \n",
       "2  2022-09-13T09:39:00+00:00      yes  2022-09-13T14:42:30+00:00    yes  NICOS  \n",
       "3  2022-09-17T00:04:34+00:00      yes  2022-09-17T01:06:23+00:00    yes  Other  \n",
       "4  2022-09-15T19:44:01+00:00      yes  2022-09-15T21:53:16+00:00    yes  NICOS  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collecting 5,000 Phishing URLs randomly\n",
    "phishurl = data0.sample(n = 5000, random_state = 12).copy()\n",
    "phishurl = phishurl.reset_index(drop=True)\n",
    "phishurl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phishurl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://1337x.to/torrent/1110018/Blackhat-2015-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://1337x.to/torrent/1122940/Blackhat-2015-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://1337x.to/torrent/1124395/Fast-and-Furio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://1337x.to/torrent/1145504/Avengers-Age-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://1337x.to/torrent/1160078/Avengers-age-o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  http://1337x.to/torrent/1110018/Blackhat-2015-...\n",
       "1  http://1337x.to/torrent/1122940/Blackhat-2015-...\n",
       "2  http://1337x.to/torrent/1124395/Fast-and-Furio...\n",
       "3  http://1337x.to/torrent/1145504/Avengers-Age-o...\n",
       "4  http://1337x.to/torrent/1160078/Avengers-age-o..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading legitimate files \n",
    "data1 = pd.read_csv(\"legitmate-websites.csv\")\n",
    "data1.columns = ['URLs']\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://graphicriver.net/search?date=this-month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://ecnavi.jp/redirect/?url=http://www.cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://hubpages.com/signin?explain=follow+Hub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://extratorrent.cc/torrent/4190536/AOMEI+B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://icicibank.com/Personal-Banking/offers/o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  http://graphicriver.net/search?date=this-month...\n",
       "1  http://ecnavi.jp/redirect/?url=http://www.cros...\n",
       "2  https://hubpages.com/signin?explain=follow+Hub...\n",
       "3  http://extratorrent.cc/torrent/4190536/AOMEI+B...\n",
       "4  http://icicibank.com/Personal-Banking/offers/o..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collecting 5,000 Legitimate URLs randomly\n",
    "legiurl = data1.sample(n = 5000, random_state = 12).copy()\n",
    "legiurl = legiurl.reset_index(drop=True)\n",
    "legiurl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legiurl.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.URL Features functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Address bar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Domain of the URL (Domain) \n",
    "def getDomain(url):  \n",
    "    domain = urlparse(url).netloc\n",
    "    if re.match(r\"^www.\",domain):\n",
    "\t    domain = domain.replace(\"www.\",\"\")\n",
    "    return domain\n",
    "\n",
    "# 2.Checks for IP address in URL (Have_IP)\n",
    "def havingIP(url):\n",
    "  try:\n",
    "    ipaddress.ip_address(url)\n",
    "    ip = 1\n",
    "  except:\n",
    "    ip = 0\n",
    "  return ip\n",
    "\n",
    "# 3.Checks the presence of @ in URL (Have_At)\n",
    "def haveAtSign(url):\n",
    "  if \"@\" in url:\n",
    "    at = 1    \n",
    "  else:\n",
    "    at = 0    \n",
    "  return at\n",
    "\n",
    "# 4.Finding the length of URL and categorizing (URL_Length)\n",
    "def getLength(url):\n",
    "  if len(url) < 54:\n",
    "    length = 0            \n",
    "  else:\n",
    "    length = 1            \n",
    "  return length\n",
    "\n",
    "# 5.Gives number of '/' in URL (URL_Depth)\n",
    "def getDepth(url):\n",
    "  s = urlparse(url).path.split('/')\n",
    "  depth = 0\n",
    "  for j in range(len(s)):\n",
    "    if len(s[j]) != 0:\n",
    "      depth = depth+1\n",
    "  return depth\n",
    "\n",
    "# 6.Checking for redirection '//' in the url (Redirection)\n",
    "def redirection(url):\n",
    "  pos = url.rfind('//')\n",
    "  if pos > 6:\n",
    "    if pos > 7:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# 7.Existence of “HTTPS” Token in the Domain Part of the URL (https_Domain)\n",
    "def httpDomain(url):\n",
    "  domain = urlparse(url).netloc\n",
    "  if 'https' in domain:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "#listing shortening services\n",
    "shortening_services = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\"\n",
    "\n",
    "# 8. Checking for Shortening Services in URL (Tiny_URL)\n",
    "def tinyURL(url):\n",
    "    match=re.search(shortening_services,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# 9.Checking for Prefix or Suffix Separated by (-) in the Domain (Prefix/Suffix)\n",
    "def prefixSuffix(url):\n",
    "    if '-' in urlparse(url).netloc:\n",
    "        return 1            # phishing\n",
    "    else:\n",
    "        return 0            # legitimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12.Web traffic (Web_Traffic)\n",
    "def web_traffic(url):\n",
    "  try:\n",
    "    #Filling the whitespaces in the URL if any\n",
    "    url = urllib.parse.quote(url)\n",
    "    rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(), \"xml\").find(\n",
    "        \"REACH\")['RANK']\n",
    "    rank = int(rank)\n",
    "  except TypeError:\n",
    "        return 1\n",
    "  if rank <100000:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# 13.Survival time of domain: The difference between termination time and creation time (Domain_Age)  \n",
    "def domainAge(domain_name):\n",
    "  creation_date = domain_name.creation_date\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "    try:\n",
    "      creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if ((expiration_date is None) or (creation_date is None)):\n",
    "      return 1\n",
    "  elif ((type(expiration_date) is list) or (type(creation_date) is list)):\n",
    "      return 1\n",
    "  else:\n",
    "    ageofdomain = abs((expiration_date - creation_date).days)\n",
    "    if ((ageofdomain/30) < 6):\n",
    "      age = 1\n",
    "    else:\n",
    "      age = 0\n",
    "  return age\n",
    "\n",
    "# 14.End time of domain: The difference between termination time and current time (Domain_End) \n",
    "def domainEnd(domain_name):\n",
    "  expiration_date = domain_name.expiration_date\n",
    "  if isinstance(expiration_date,str):\n",
    "    try:\n",
    "      expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "    except:\n",
    "      return 1\n",
    "  if (expiration_date is None):\n",
    "      return 1\n",
    "  elif (type(expiration_date) is list):\n",
    "      return 1\n",
    "  else:\n",
    "    today = datetime.now()\n",
    "    end = abs((expiration_date - today).days)\n",
    "    if ((end/30) < 6):\n",
    "      end = 0\n",
    "    else:\n",
    "      end = 1\n",
    "  return end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML and JavaScript based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. IFrame Redirection (iFrame)\n",
    "def iframe(response):\n",
    "  if response == \"\":\n",
    "      return 1\n",
    "  else:\n",
    "      if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "          return 0\n",
    "      else:\n",
    "          return 1\n",
    "\n",
    "# 16.Checks the effect of mouse over on status bar (Mouse_Over)\n",
    "def mouseOver(response): \n",
    "  if response == \"\" :\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(\"<script>.+onmouseover.+</script>\", response.text):\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "\n",
    "# 17.Checks the status of the right click attribute (Right_Click)\n",
    "def rightClick(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if re.findall(r\"event.button ?== ?2\", response.text):\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "# 18.Checks the number of forwardings (Web_Forwards)    \n",
    "def forwarding(response):\n",
    "  if response == \"\":\n",
    "    return 1\n",
    "  else:\n",
    "    if len(response.history) <= 2:\n",
    "      return 0\n",
    "    else:\n",
    "      return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction function of these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureExtraction(url,label):\n",
    "\n",
    "  features = []\n",
    "  #Address bar based features (10)\n",
    "  features.append(getDomain(url))\n",
    "  features.append(havingIP(url))\n",
    "  features.append(haveAtSign(url))\n",
    "  features.append(getLength(url))\n",
    "  features.append(getDepth(url))\n",
    "  features.append(redirection(url))\n",
    "  features.append(httpDomain(url))\n",
    "  features.append(tinyURL(url))\n",
    "  features.append(prefixSuffix(url))\n",
    "  \n",
    "  #Domain based features (4)\n",
    "  dns = 0\n",
    "  try:\n",
    "    domain_name = whois.whois(urlparse(url).netloc)\n",
    "  except:\n",
    "    dns = 1\n",
    "\n",
    "  features.append(dns)\n",
    "  features.append(web_traffic(url))\n",
    "  features.append(1 if dns == 1 else domainAge(domain_name))\n",
    "  features.append(1 if dns == 1 else domainEnd(domain_name))\n",
    "  \n",
    "  # HTML & Javascript based features (4)\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "  except:\n",
    "    response = \"\"\n",
    "  features.append(iframe(response))\n",
    "  features.append(mouseOver(response))\n",
    "  features.append(rightClick(response))\n",
    "  features.append(forwarding(response))\n",
    "  features.append(label)\n",
    "  \n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Compute URLs and save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 1), (5000, 8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legiurl.shape, phishurl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the feautres & storing them in a list\n",
    "legi_features = []\n",
    "label = 0\n",
    "for i in range(0, 10):\n",
    "  url = legiurl['URLs'][i]\n",
    "  legi_features.append(featureExtraction(url,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the feautres & storing them in a list\n",
    "legi_features = []\n",
    "label = 0\n",
    "\n",
    "inputs = range(50)\n",
    "\n",
    "def process(index):\n",
    "    url = legiurl['URLs'][index]\n",
    "    legi_features.append(featureExtraction(url,label))\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "results = Parallel(n_jobs=num_cores)(delayed(process)(index) for index in inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the list to dataframe\n",
    "feature_names = ['Domain', 'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth','Redirection', \n",
    "                      'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', \n",
    "                      'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over','Right_Click', 'Web_Forwards', 'Label']\n",
    "\n",
    "legitimate = pd.DataFrame(legi_features, columns= feature_names)\n",
    "legitimate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the extracted legitimate URLs fatures to csv file\n",
    "legitimate.to_csv('legitimate.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phishing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phishurl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the feautres & storing them in a list\n",
    "phish_features = []\n",
    "label = 1\n",
    "for i in range(0, 5000):\n",
    "  url = phishurl['url'][i]\n",
    "  phish_features.append(featureExtraction(url,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the list to dataframe\n",
    "feature_names = ['Domain', 'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth','Redirection', \n",
    "                      'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Web_Traffic', \n",
    "                      'Domain_Age', 'Domain_End', 'iFrame', 'Mouse_Over','Right_Click', 'Web_Forwards', 'Label']\n",
    "\n",
    "phishing = pd.DataFrame(phish_features, columns= feature_names)\n",
    "phishing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the extracted legitimate URLs fatures to csv file\n",
    "phishing.to_csv('phishing.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concate phishing and legit URLs into one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating the dataframes into one \n",
    "urldata = pd.concat([legitimate, phishing]).reset_index(drop=True)\n",
    "urldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data in CSV file\n",
    "urldata.to_csv('urldata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('datascience')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "431952e8195d73cd39404705109eaefd639dd3fb8d4e9cb1f35f6f6a5f324ad3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
